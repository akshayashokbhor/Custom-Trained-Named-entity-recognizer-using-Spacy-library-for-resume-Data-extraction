# -*- coding: utf-8 -*-
"""Untitled29.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fd7gA413recU6BKPjk32MqEv_aSdXuVY

# **Resume and CV auto ML Shortlisting**
"""

import spacy
import pickle
import random



from google.colab import drive
drive.mount('/content/drive')

train_data = pickle.load(open('/content/drive/MyDrive/train_data.pkl', 'rb'))

len(train_data)

train_data[0]

for _, annotation in train_data:
  for ent in annotation['entities']:
    print(ent[2])

"""start with blank spacy model"""

nlp = spacy.blank('en')

"""Train with our custom train_data containing resume with their annotations

and update that in our nlp model
"""

def train_model(train_data):
    if 'ner' not in nlp.pipe_names:
        ner = nlp.create_pipe('ner')
        nlp.add_pipe(ner, last = True)
    
    for _, annotation in train_data:
        for ent in annotation['entities']:
            ner.add_label(ent[2])
            
    
    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']
    with nlp.disable_pipes(*other_pipes):  # only train NER
        optimizer = nlp.begin_training()
        for itn in range(30):
            print("Statring iteration " + str(itn))
            random.shuffle(train_data)
            losses = {}
            index = 0
            for text, annotations in train_data:
                try:
                    nlp.update(
                        [text],  # batch of texts
                        [annotations],  # batch of annotations
                        drop=0.2,  # dropout - make it harder to memorise data
                        sgd=optimizer,  # callable to update weights
                        losses=losses)
                except Exception as e:
                    pass
                
            print(losses)

train_model(train_data)

"""save model to google drive"""

nlp.to_disk('/content/drive/MyDrive/NLP NER model/nlp_model')

"""load the model using spacy library"""

loaded_nlp_model = spacy.load('/content/drive/MyDrive/NLP NER model/nlp_model')

train_data[0][0]

"""performing testing on our earlier seen data"""

doc = loaded_nlp_model(train_data[0][0])
for ent in doc.ents:
    print(f'{ent.label_.upper():{30}}- {ent.text}')

"""Testing with unseen data"""

!pip install PyMuPDF

import sys, fitz
fname = '/content/drive/MyDrive/Smith Resume.pdf'
doc = fitz.open(fname)
doc

text = ""
for page in doc:
    text = text + str(page.getText())

tx = " ".join(text.split('\n'))
print(tx)

"""# **RESULT**"""

doc = loaded_nlp_model(tx)
for ent in doc.ents:
    print(f'{ent.label_.upper():{30}}- {ent.text}')